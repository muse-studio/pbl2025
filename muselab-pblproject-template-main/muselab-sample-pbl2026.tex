% !TEX root = _main.tex
% ========================================
% 卒業論文　本文
% ========================================
%1------*------*------*------*------*------*------*------*------*------*------*------*
\section{はじめに}


近年，デジタル技術の発展により，音楽と映像を組み合わせた表現が多様化している。特に，ライブパフォーマンスや舞台演出において，
音楽の進行に応じて映像が変化する演出は，観客に対して強い没入感を与える手法として注目されている。このような音楽と映像の連動表現は，
事前に制作された映像を再生するだけでなく，演奏中の音楽的要素をリアルタイムに反映させることが求められている。

しかし，映像制作や映像演出には多くの時間と手間，ならびに専門的な知識が必要であり，音楽演奏と並行して映像を操作することは容易ではない。
そのため，映像演出は演奏とは切り離され，別の操作者によって制御される場合が多いのが現状である。また，演奏者自身が演奏中に映像を制御することを前提とした
ステムに関する研究や事例は少なく，音楽表現と映像表現を演奏行為の中で統合する手法は研究事例が限られており，現在も発展途上の段階にある。

さらに，演奏中の操作が複雑である場合，演奏そのものに支障をきたす可能性がある。このため，演奏者の負担を最小限に抑え，演奏の流れを妨げることなく直感的に
映像を制御できる仕組みが求められている。このような課題は，音楽表現と視覚表現の一体化を実現する上で重要な検討事項である。

そこで本研究では，ピアノ演奏に基づいて映像をリアルタイムに制御・生成するシステムの構築を目的とする。具体的には，MIDIキーボードから取得したノート番号
およびベロシティ情報，ならびにUSBフットペダルからの入力を用いて，演奏内容に応じた映像表現を実現する。映像の制御および制作にはTouchDesignerを用い，
演奏中の入力情報を即時に映像パラメータへ反映させることで，演奏と映像が連動した表現を可能とする。

また，本研究では映像表現の一要素として生成AIを用いた視覚表現を取り入れる。歌詞を含む楽曲に対しては，Pythonを用いて入力した歌詞データをもとに画像生成を行い
，楽曲内容に対応した映像素材を生成する。一方，歌詞を持たない楽曲に対しては，曲の雰囲気や印象を表す情報をもとに生成AIを用いて視覚表現を生成する手法を採用
している。

さらに，本システムは生成された画像を静止画として映像演出に用いるだけでなく，動画素材を映像として利用することも可能な構成となっている。これにより，楽曲の特性に
応じて柔軟に映像表現を選択でき，音楽的要素および言語的要素の双方を含んだ映像演出をリアルタイムパフォーマンスに組み込むことも目標としている。

%2------*------*------*------*------*------*------*------*------*------*------*------*
\section{関連研究}

あとで書く------*------*------*------*------*------*------*------*------*------*------*------*
本研究で構築したシステムは、演奏者の電子ピアノの打鍵動作を入力信号として受け取り、
それをトリガーとして音楽を生成する Max8\cite{La}と、音楽に連動した映像を制作する
Processing\cite{Lb}を組み合わせたものである(図１)。演奏者が電子ピアノの特定の鍵盤を押す
と、その打鍵動作がトリガー信号としてMax8に伝達され、システムが作動して音楽が自動
生成される。同時に、その音楽データはUDP（ユーザデータグラムプロトコル）を通じて
Processing に送信され、リアルタイムで映像が生成される仕組みとなっている。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f1.png}
    \caption{システムの概要図}
    \label{fig:sample1}
\end{figure}
------*------*------*------*------*------*------*------*------*------*------*------*------*

%3------*------*------*------*------*------*------*------*------*------*------*------*
\section{システムの概要 }
\subsection{システム全体構成}
本研究で提案するシステムは，ピアノ演奏および生成AIによって作成された映像素材を用いて，演奏内容に応じた映像表現をリアルタイムに制御・出力することを目的としている。
本システムは，演奏情報および映像素材生成のための入力を受け取り，TouchDesigner上で映像制御を行い，最終的にスクリーンへ映像を出力する構成となっている。

システム全体の流れは大きく二つに分かれる。一つは，Pythonで構築した歌詞・イメージ入力画面から生成AIを用いて映像素材を生成し，その結果をTouchDesignerに取り込む流れである。
もう一方は，MIDIキーボードおよびUSBフットペダルから取得した演奏情報をTouchDesignerへ入力し，映像演出を制御する流れである。これら二つの情報が統合されることで，
多様な映像表現に対応可能なシステムの構築を目指している。

【システム概要図】

\subsection{使用機材およびソフトウェア}
本システムで使用する主な機材は，MIDIキーボード，USBフットペダル，および処理を行うPCである。MIDIキーボードはピアノ演奏情報の入力装置として使用し，
USBフットペダルは演奏中の映像および歌詞の切り替え操作を行うために用いる。

使用ソフトウェアとしては，映像制御および映像制作にTouchDesignerを使用する。また，歌詞や曲のイメージ情報の入力にはPythonを用い，映像素材の生成には
OpenAIのAPIを利用している。

\subsection{映像出力およびパフォーマンス環境}

本システムによって制御された映像は，スクリーンに対して一画面で投影される。ライブパフォーマンスでの使用を想定し，演奏者のピアノ演奏と映像が同期して提示される構成としている。これにより，音楽の進行や演奏表現に応じて視覚的な変化が生じ，観客に対して音楽と映像が一体となった表現を提示することが可能となる。

パフォーマンス中には，演奏者がUSBフットペダルを用いて映像や歌詞の切り替えを行う。フットペダルによる操作を採用することで，手を使わずに映像制御を行うことができ，演奏動作
への影響を最小限に抑えている。また，演奏者は演奏の流れに合わせて必要なタイミングで映像を切り替えることができるため，ライブパフォーマンスにおける即時性にも対応可能である。

このような構成により，演奏行為を中心としながらも，演奏者自身が映像表現に直接関与できる環境を実現している。結果として，音楽表現と映像表現が相互に影響し合う
ライブパフォーマンスが可能となり，演奏行為と同期した視覚表現を実現している。

%4------*------*------*------*------*------*------*------*------*------*------*------*
\section{画像生成システム }
本研究では，ピアノ演奏と連動した映像演出に使用する映像素材を生成するため，生成AIを用いた画像生成システムを構築した。本システムはPython上で動作するGUIアプリケーション
として実装されており，OpenAIの画像生成APIおよびGUIライブラリであるTkinterを用いて構成されている。

ユーザインタフェースでは，最大20行までのテキスト入力が可能であり，各行ごとに「歌詞」または「インスト」を選択することができる。歌詞を含む楽曲の場合には歌詞をそのまま入力し，
歌詞を持たない楽曲の場合には楽曲の雰囲気やイメージを文章として入力することで，生成AIによる画像生成を行う。生成された画像はPNGファイルとして保存され，TouchDesignerに取り込むことで映像演出に利用される。

この曲を選んだ理由は、まず楽譜（図 ２）を見ると、ほとんどが十六分音符で構成されて
おり、プログラミングが比較的容易であると判断したからである。また、私自身がショパン
のエチュードの中でこの曲を最も気に入っており、絶え間なく奏でられる美しいアルペジ
オの魅力を最大限に引き出したいと感じたからである。 

今回の研究では、楽譜の特徴を活用し、演奏者の負担を軽減するための自動演奏システム
を構築した。具体的には、十六分音符が6つまとまったフレーズのうち、最初の音（図３の
赤丸で示された部分）のみを演奏者が弾けばよい仕組みを採用した。システムはこの最初の
音を検知すると、残りの 5 つの音を生成し、演奏者の弾いた音に自然に続くように再生さ
れる。この方法により、演奏者の指の動きを補助しつつ、楽曲の持つ滑らかさとテンポ感を
維持することを目指した。図４はシステムを利用する際、演奏者が実際に演奏する楽譜の一
部であり、元の楽譜（図３）と比べ演奏が容易になっている。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f2.png}
    \caption{「エオリアンハープ」楽譜 }
    \label{fig:sample2}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f3.png}
    \caption{「 エオリアンハープ」楽譜の一部 }
    \label{fig:sample3}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f4.png}
    \caption{演奏者が弾く楽譜の一部}
    \label{fig:sample4}
\end{figure}

%5------*------*------*------*------*------*------*------*------*------*------*------*
\section{TouchDesignerを用いた映像制作 }
パソコンのキーボードや電子ピアノの鍵盤を使い、赤丸で囲まれた音符に対応するキーや
鍵盤を押すと、その音に続くフレーズが自動的に再生されるようにプログラムされている。
具体的には、最初の6連符「E♭, A♭, C, E♭, A♭, C」の場合、最初の「E♭」が打鍵され
るとシステムが作動する。Max8のmetroオブジェクトを使用して指定されたテンポに従っ
て、図 5-A の部分でリストに格納された数値が順に処理され、それに対応する音が生成さ
れる仕組みになっている。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f5.png}
    \caption{「Max８で構築したプログラム}
    \label{fig:sample5}
\end{figure}


このシステムは右手パートと左手パートに分けて設計し、それぞれ個別に制作した。また
テンポについては、演奏者の好みや技術レベルに柔軟に対応できるよう工夫した。具体的に
は、図5-Bで1つ前の音が押されてから次の音が押されるまでの時間を計測し、その時間
を6等分することで、テンポを自然に調整できる仕組みを取り入れている（図6）。これに
より、演奏者は自身の演奏スタイルに合わせて、滑らかな演奏が可能となる。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f6.png}
    \caption{テンポ計測}
    \label{fig:sample6}
\end{figure}

\subsection{Max8からデータを送信する方法 }
Max８から外部のソフトにデータを送信するために
「udpsend」というオブジェクトを使用した。「udpsend 
[IP アドレス] [ポート番号]」と指定することで、UDP
を介してデータをネットワーク経由で送信している（図
7）。具体的には、Max8からProcessingに向けて、指定
したIP アドレスとポート番号にデータを送る仕組みを
構築している。この方法により、Max8で生成されたデ
ータを Processing が受信し、リアルタイムな連携を実
現している。

また、図7の「prepend /abc」は、メッセージの先頭に「/abc」というシンボルを付加す
るオブジェクトである。これにより、Max パッチ内で他のオブジェクトから送られてきた
メッセージを「/abc」で始まる形式に変換し、その後にデータや引数を追加することが可能
となる。たとえば、他のオブジェクトから「hello」というメッセージが送られた場合、
「prepend /abc」を通過すると、Maxパッチ内では「/abc hello」という形式のメッセージ
に変換される。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f7.png}
    \caption{Max8からデータを送る}
    \label{fig:sample7}
\end{figure}

\section{映像制作 }

\subsection{Processing について}
Processing はビジュアルアートに適したプログラミング言語であり、同時にIDE（総合開
発環境） でもある。基本的にJavaに似ているが、Javaより記述がシンプルで、Processing 
独自のルールも存在している\cite{Ld}。

Processing を利用するメリットは、グラフや図形をアニメーションで簡単に実行できる点
である。例えば、C言語やPythonなどの他のプログラミング言語でアニメーションを実行
しようとすると、専用のライブラリやフレームワークをインストールする必要があり、さら
に複雑な設定や準備が求められることが多い。しかし、Processingではそのような手間がな
く、単体でアニメーションを実行するための機能が備わっている。そのため、すぐに視覚的
に結果を確認することができ、開発の進行が非常にスムーズである。 

また、Processingは視覚的な表現に特化しており、図形やグラフ、アニメーションを簡単
に作成できる。そのため、コードの記述に集中しやすいという利点がある。さらに、
Processing には基本的な描画機能に加え、デフォルトで豊富な機能が備わっている。例え
ば、画像の読み込み、音声の再生、センサー入力などを簡単に実装できる。これらの機能が
最初から備わっているため、複雑なライブラリの追加や、設定を行う手間が省ける。したが
って、初心者でもある程度のソースコードを記述するだけで、目的の結果を得ることができ
る。

一方で、Processing にはいくつかのデメリットも存在する。最も顕著な点は、実行速度が
遅いということである。Processingはインタプリタ型の言語であり、コンパイル型言語であ
るC言語やC♯と比較すると、実行速度が遅くなる傾向がある。また、処理能力が高く求め
られる場合、特に複雑な計算やリアルタイムでの音声・映像処理においては、パフォーマン
スの低下が見られることがある。このため、音楽と映像を同期させるようなシステムにおい
て、ラグが発生する可能性がある。音楽と映像がリアルタイムで密接に連携する場合、その
タイミングのズレが視覚的にも聴覚的にも影響を与える可能性があり、これが一つの懸念
点となる。

\subsection{コードの説明}
本システムは、Processingを使用してピアノの鍵盤インターフェースを描画し、鍵盤が押
された際に視覚効果を生成する機能を提供するものである。映像処理についての概要図は
図8に示す。コードは主に以下の部分に分かれている。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{f8.png}
    \caption{映像処理についての概要図}
    \label{fig:sample8}
\end{figure}

まず、setup()メソッドにおいて、画面サイズを2560x1320ピクセルに設定し、鍵盤の幅を
計算する。さらに、OscP5 ライブラリを使用して、外部ソフトウェアやハードウェアから
のOSC(Open Sound Control)メッセージ\cite{Le}を受信する準備も行う。 

次に、drawKeyboard()メソッドにより 88 鍵のピアノ鍵盤が描画される。この部分では、
白鍵と黒鍵の幅を計算し、各鍵を描画している。鍵盤が押されると色が変わり、視覚的に押
された状態が示される。

視覚効果については、FlyingObjectクラスが担当し、鍵盤が押されると四角形が画面上に
現れ、上方向に移動しながら色が変化する。また、Particleクラスは炎のような粒子を生成
し、指定された速度で動かしながら透明度を減少させ、視覚的な動きを加える。さらに、
FloatingParticle クラスはランダムに浮遊する粒子を生成し、上昇しながら徐々に消えてい
く効果を生み出す。

oscEvent()メソッドでは、外部から送られてくるOSCメッセージを受信し、方向値を解析
して押された鍵盤のインデックスをマッピングする処理を行う。このインデックスに対応
した鍵盤が押されると、その鍵盤に関連する視覚効果が生成される。

ユーザーインタラクションは、keyReleased()メソッドによって管理される。ユーザーが鍵
盤のキーを離した際、鍵盤の状態がリセットされる。また、mapKeyToIndex()メソッドで
は、受信した方向値に基づいて押された鍵のインデックスを計算し、そのインデックスに対
応する視覚効果が発生する仕組みとなっている。

全体として、このシステムは、ピアノの鍵盤を押すことで視覚効果を生成し、OSCメッセ
ージに反応してインタラクションを管理する仕組みを提供するものとなっている。 

\subsection{デザインについて}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{f9.png}
    \caption{製作した映像}
    \label{fig:sample9}
\end{figure}

本システムのデザインは、視覚的に魅力的でインタラクティブなピアノ鍵盤インターフェ
ースを提供することを目標としており、デザインは以下の要素を中心に構成されている（図
9）。

まず、88 鍵のピアノ鍵盤が画面下部に水平に配置され、白鍵と黒鍵が正確に描画される。
白鍵の幅は画面幅に応じて動的に計算され、黒鍵は白鍵の 60％の幅で表示されるため、実
際のピアノ鍵盤に忠実なレイアウトが実現されている。鍵盤が押されると、白鍵は少し暗く、
黒鍵は明るく表示されることで、どの鍵盤が押されたのかが視覚的に明確に示され、インタ
ラクティブな体験が強調される。　

視覚効果としては、鍵盤が押されるとFlyingObjectクラスによって四角形が画面上に飛び
出し、色が虹色に変化する。これにより、音楽が演奏される感覚が視覚的に強調される。ま
た、Particle クラスによって炎のような粒子が放出され、FloatingParticleクラスではランダ
ムに浮遊する粒子が生成され、押された鍵盤に対して動的な反応が表現される。 
視覚的な特徴として、背景は黒色に設定され、鍵盤や視覚効果は白や虹色、青色などの鮮
やかな色で描画される。これにより、高いコントラストが生まれ、視覚的に目を引く効果が
得られ、画面上部にはタイトル「Chopin Etude Op.25 No.1 'Aeolian Harp'」が表示される
ようになっている。

このシステムでは、音楽演奏に伴う動的な視覚効果を取り入れ、鍵盤操作に連動したイン
タラクティブな体験を実現することを目指して、デザイン設計を行っている。鍵盤が押され
るたびに視覚効果が現れることで、音楽と視覚表現を組み合わせた新しい表現の形を模索
している。



\subsection{処理速度の課題}
最初は背景に動画を使用することを考えていたが、処理が重くなる問題が発生した。試し
に画像を背景として使って実行したところ、四角形の動きが非常に遅くなった。画像はでき
るだけ圧縮して軽くした上で実行してみたが、依然としてうまく動作しなかった。そのため、
動画を背景として使用するのは難しいと判断した。その後、背景をグラデーションに変更し
ようとした際にも、同様に動作が遅くなる問題が発生した。そのため、背景デザインはシン
プルなものにしたが、現状の方法では満足できていないため、より効率的な方法を模索して
いる。 

%6------*------*------*------*------*------*------*------*------*------*------*------*
\section{足キーボードを用いた映像制御について }
最終的には、映像をプロジェクターで投影し、それをピアノと連動させた形で演奏を行う
ライブパフォーマンスを実現したいと考えている。このシステムでは、音楽と映像のシンク
ロ性を重視し、視覚と聴覚を融合させた新しい表現方法を追求していきたい。演奏者が楽曲
を弾くと、それに連動して映像がリアルタイムで変化する仕組みを構築し、演奏と映像が一
体となった没入感のあるパフォーマンスを目指している。また、このシステムは多くの人に
利用してもらえるものにしたいと考えており、幅広いユーザー層に対応できる設計を目指
している。

\subsection{システムの改善点 }
システムの改善点として、現時点では自分自身が使用することを前提に設計を行っている
ため、以下の問題点を詳細に検討する必要がある。

まず、楽譜が読めない利用者でも操作可能なシステムとするか、それとも一定以上の演奏
技術を有する利用者を対象とするかという点について、利用者層の明確化が必要である。こ
の点を明確にすることにより、システムの目的や設計方針がより具体的に定まると考えら
れる。

次に、演奏中に発生するミスへの対応が現状では考慮されていない点が挙げられる。例え
ば、演奏者が途中で間違えた場合に、その場で修正し再開できる仕組みを整える必要がある。
また、演奏の途中から開始したい場合や特定の箇所のみを繰り返して練習する機能につい
ても、現時点では未対応であるため、これらの機能も実装する必要があると考えている。

さらに、現在のシステムでは、演奏中にミスが生じた際に全て最初からやり直さなければ
ならない設計となっており、この点は生演奏の実用性を著しく損なう要因となっている。生
演奏に対応するシステムとするためには、リアルタイムでの柔軟な対応や、演奏の進行状況
を記録し、途中から再開できる仕組みの導入が必要不可欠である。

以上のように、利用者層の明確化や演奏中の柔軟な対応を含むシステムの設計改善を進め
ることで、より多くの利用者が快適に使用できる実用的なシステムを目指すことができる
と考えている。

%7------*------*------*------*------*------*------*------*------*------*------*------*
\section{実演について }
本研究では、Max8を用いた自動演奏システムとProcessingを活用した映像作品を組み合
わせた表現の可能性を探求した。具体的には、ショパンのエチュードOp.25-1 を基に、演
奏者の負担を軽減するシステムを構築し、それに連動した映像を制作することで、音楽と視
覚が融合する新しいパフォーマンスを提案した。 

研究を通じて、自動演奏システムの応用可能性やProcessingを用いた映像制作の利便性を
確認できた一方で、システムの処理速度やリアルタイム性といった課題も明らかとなった。
これらの課題は、演奏者の技術や目的に応じた利用者層の明確化や、演奏中のエラー対応機
能の実装など、今後の発展的な取り組みを通じて改善をしていく必要があると考える。 

今後は、音楽と映像が完全に同期するリアルタイムシステムを目指し、ライブパフォーマ
ンスに対応できるシステムの実現を目標とする。特に、システムの処理速度や安定性を向上
させることで、演奏と映像の同期精度を高め、視覚的な遅延を減少させる必要があると考え
る。さらに、多様なユーザーが利用できる汎用性の高い設計を追求し、音楽と映像の新たな
表現方法を提供することで、幅広い人々に感動を与える作品を制作したい。また、将来的に
は、インタラクティブな要素を追加し、ユーザーが自身の演奏に対してリアルタイムで反応
する新しい形態のパフォーマンスを構築したいと考えている。 

%8------*------*------*------*------*------*------*------*------*------*------*------*
\section{課題と今後の発展について }

%9------*------*------*------*------*------*------*------*------*------*------*------*
\section{まとめ }
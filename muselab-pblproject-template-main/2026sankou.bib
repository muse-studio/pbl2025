@misc{CVMusic,
  title = {サイバードリームズ:拡張現実における音楽の可視化 \textbar シュプリンガー・ネイチャー・リンク},
  urldate = {2026-01-20},
  howpublished = {https://link.springer.com/chapter/10.1007/978-3-030-42097-0\_12?utm\_source=chatgpt.com},
  file = {C:\Users\mizuki\Zotero\storage\FZIG6JJH\978-3-030-42097-0_12.html}
}

@misc{DALLE3,
  title = {{DALL{$\cdot$}E 3}},
  urldate = {2026-01-05},
  abstract = {DALL{$\cdot$}E 3 は、以前のシステムよりもはるかに多くのニュアンスと詳細を理解するため、アイデアを非常に正確な画像へ簡単に変換できます。},
  howpublished = {https://openai.com/ja-JP/index/dall-e-3/},
  langid = {japanese},
  file = {C:\Users\mizuki\Zotero\storage\TMFJZQ83\dall-e-3.html}
}

@article{erdmann,
  title = {Development and Evaluation of a Mixed Reality Music Visualization for a Live Performance Based on Music Information Retrieval},
  author = {Erdmann, Matthias and {von Berg}, Markus and Steffens, Jochen},
  year = 2025,
  month = mar,
  journal = {Frontiers in Virtual Reality},
  volume = {6},
  publisher = {Frontiers},
  issn = {2673-4192},
  doi = {10.3389/frvir.2025.1552321},
  urldate = {2026-01-05},
  abstract = {The present study explores the development and evaluation of a mixed reality music visualization for a live music performance. Real-time audio analysis and crossmodal correspondences were used as design guidelines for creating the visualization, which was presented through a head-mounted-display. To assess the impact of the music visualization on the audience's aesthetic experience, a baseline visualization was designed, featuring the same visual elements but with random changes of color and movement. The audience's aesthetic experience of the two conditions (i.e., listening to the same song with different visualizations) was assessed using the Aesthetic Emotions Scale (AESTHEMOS) questionnaire. Additionally, participants answered questions regarding the perceived audiovisual congruence of the stimuli and questionnaires about individual musicality and aesthetic receptivity. The results show that the visualization controlled by real-time audio analysis was associated with a slightly enhanced aesthetic experience of the audiovisual composition compared to the randomized visualization, thereby supporting similar findings reported in the literature. Furthermore, the tested personal characteristics of the participants did not significantly affect aesthetic experience. Significant correlations between these characteristics and the aesthetic experience were observed only when the ratings were averaged across conditions. An open interview provided deeper insights into the participants' overall experiences of the live music performance. The results of the study offer insights into the development of real-time music visualization in mixed reality, examines how the specific audiovisual stimuli employed influence the aesthetic experience, and provides potential technical guidelines for creating new concert formats.},
  langid = {english},
  keywords = {aesthetic experience,concert formats,mixed reality,music information retrieval,music visualization,real-time audio analysis},
  file = {C:\Users\mizuki\Zotero\storage\UAG3CD2V\Erdmann et al. - 2025 - Development and evaluation of a mixed reality music visualization for a live performance based on mu.pdf}
}

@misc{graf,
  title = {An {{Audio-Driven System For Real-Time Music Visualisation}}},
  author = {Graf, Max and Opara, Harold Chijioke and Barthet, Mathieu},
  year = 2021,
  month = jun,
  number = {arXiv:2106.10134},
  eprint = {2106.10134},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.10134},
  urldate = {2026-01-05},
  abstract = {Computer-generated visualisations can accompany recorded or live music to create novel audiovisual experiences for audiences. We present a system to streamline the creation of audio-driven visualisations based on audio feature extraction and mapping interfaces. Its architecture is based on three modular software components: backend (audio plugin), frontend (3D game-like environment), and middleware (visual mapping interface). We conducted a user evaluation comprising two stages. Results from the first stage (34 participants) indicate that music visualisations generated with the system were significantly better at complementing the music than a baseline visualisation. Nine participants took part in the second stage involving interactive tasks. Overall, the system yielded a Creativity Support Index above average (68.1) and a System Usability Scale index (58.6) suggesting that ease of use can be improved. Thematic analysis revealed that participants enjoyed the system's synchronicity and expressive capabilities, but found technical problems and difficulties understanding the audio feature terminology.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Multimedia},
  file = {C\:\\Users\\mizuki\\Zotero\\storage\\WWUSM37F\\Graf et al. - 2021 - An Audio-Driven System For Real-Time Music Visualisation.pdf;C\:\\Users\\mizuki\\Zotero\\storage\\49F2XGN9\\2106.html}
}

@misc{haruyokoi,
  title = {松任谷由実 - 春よ、来い},
  author = {{松任谷由実}},
  year = 2019,
  month = aug,
  urldate = {2026-01-05},
  abstract = {1994.10.24 Release 26th Single「春よ、来い」 1994.11.25 Release 26th Album「THE DANCING SUN」収録曲}
}

@misc{Howl,
  title = {Joe {{Hisaishi}} - {{Merry-Go-Round}} (from '{{Howl}}'s {{Moving Castle}}')},
  author = {{Joe Hisaishi Official}},
  year = 2020,
  month = feb,
  urldate = {2026-01-05},
  abstract = {Official music video by Joe Hisaishi  ►LINK: https://deccagold.lnk.to/DreamSongs ►Spotify: https://deccagold.lnk.to/ThisIsHisaishi}
}

@misc{KAKEN,
  title = {視聴覚コンテンツにおける映像と音楽の適合性の効果の実験心理学的検討},
  journal = {KAKEN},
  urldate = {2026-01-19},
  abstract = {本研究は，短い映画のような視聴覚コンテンツにおいて，映像と音楽がどのような情報を含むときに「適合している」（一体のものである）と感じられるのかや，その適合・不適合が視聴覚コンテンツ全体の解釈にどのような影響を与えるのか（例えば，不適合な場合に，どのような感性的効果が生み出されるのか）を，そのメカニズムを含めて，実験心理学的な手法により明らかにしようとするものである。},
  howpublished = {https://kaken.nii.ac.jp/grant/KAKENHI-PROJECT-22K03199/},
  file = {C:\Users\mizuki\Zotero\storage\Y684TSZQ\KAKENHI-PROJECT-22K03199.html}
}

@article{ogawa,
  title = {1視点固定型ライブ映像における映像・音響表現自動付与による音楽体験拡張},
  author = {剣二郎, 小川 and 聡史, 中村},
  year = 2025,
  month = dec,
  journal = {情報処理学会論文誌},
  volume = {66},
  number = {12},
  pages = {1715--1724},
  urldate = {2026-01-05},
  abstract = {軽音楽団体でのライブ映像配信では，撮影・配信のための機材が揃っていないことから1視点から撮影することが多く，またこういった映像は臨場感が伝わりにくく離脱者が多い．ここで，適した頻度のカットによる印象，視覚と聴覚の情報の一致による認知，感性への効果に関する研究が報告されており，映像表現，またそれに合わせて音響表現を加えることでその効果を高められるのではないかと考えた．そこで本研究では，映像・音響表現の付与により，ライブ映像視聴時の音楽体験を向上させる手法を提案する．アンケートによる主観評価を行い，没入感，社会的存在感，演者への興味度を比較することで提案手法の効果を検証した．その結果，すべての評価軸において，映像表現を付与することが有効であることが明らかになった．また，1視点固定型ライブ映像に対する満足度が高い場合は，映像表現と音響表現を組み合わせることにより音楽体験を向上させる可能性が示唆された．},
  file = {C:\Users\mizuki\Zotero\storage\XUBU334P\剣二郎 と 聡史 - 2025 - 1視点固定型ライブ映像における映像・音響表現自動付与による音楽体験拡張.pdf}
}

@misc{Processing,
  title = {Welcome to {{Processing}}!},
  journal = {Processing},
  urldate = {2026-01-05},
  abstract = {Processing is a flexible software sketchbook and a language for learning how to code. Since 2001, Processing has promoted software literacy within the visual arts and visual literacy within technology\dots},
  howpublished = {https://processing.org//},
  langid = {american},
  file = {C:\Users\mizuki\Zotero\storage\EG6TH864\processing.org.html}
}

@misc{secretBase,
  title = {{{ZONE}}「secret Base ～君がくれたもの～」{{MUSIC VIDEO}}},
  author = {{MUSIC Liverary}},
  year = 2021,
  month = jul,
  urldate = {2026-01-05},
  abstract = {「secret base ～君がくれたもの～」の配信はこちら https://lnk.to/zonesecretbase}
}

@misc{Sora,
  title = {{Sora}},
  urldate = {2026-01-05},
  abstract = {Turn your ideas into videos with hyperreal motion and sound.},
  howpublished = {https://openai.com/ja-JP/sora/},
  langid = {japanese}
}

@misc{TouchDesigner,
  title = {{TouchDesigner}},
  journal = {株式会社ボーンデジタル},
  urldate = {2026-01-05},
  abstract = {TouchDesignerは、リアルタイムグラフィックス、インタラクティブアート、メディアサーバー、プロジェクションマッピング、VR開発、照明、ライブショーなど、幅広い用途に対応する強力なビジュアル開発プラットフォームです。直感的なインターフェースと豊富な機能により、クリエイティブなアイデアを迅速に具現化できます。 ~ 概要 TouchDesignerは、アプリケーション構築に特化した強力なプラットフォームであり、アプリケーションエンジンとユーザーインターフェースの両方を統合的に開発できます。シンプルな機能プロトタイプから完成度の高い洗練されたアプリケーションまで、あらゆるものを迅速にプロトタイプ作成し、作成することができます。 ~ 主な用途と特長 TouchDesignerは多岐にわたる分野で活用され、それぞれの用途において優れた機能を発揮します。 アプリケーション構築 広範なコントロールパネルセット: カスタムインターフェースとロジックを構築するための広範なコントロールパネルセットを提供します。 多様な入力サポート: マウス、タッチスクリーン、3D仮想環境、ジェスチャー入力など、あらゆる種類のインタラクションをサポートします。 モジュール式で再利用可能なコンポーネント: カスタムパラメータを持つモジュール式で再利用可能なコンポーネントを設計できます。 事前の視覚化: インスタレーションやライブショーの事前の視覚化を容易にし、物理的な構築前に創造的な実験と技術的なソリューションのテストを可能にします。 すぐに使えるUIガジェット: ドラッグ＆ドロップでパネルを作成するためのすぐに使えるUIガジェットが含まれています。 ファイルとコンポーネントのプライバシーコントロール: ファイルとコンポーネントのプライバシーを保護する機能を提供します。 利点: 迅速なプロトタイプ作成、オンサイト前の機能確認、包括的なアプリケーション開発のための統合された環境。 ~ ハイパフォーマンスメディアシステム 高解像度・高フレームレート再生: HAP Q、Cineform、H.264、H.265/HEVCなどの高度なコーデックをサポートし、最大32K解像度、4K 120Hzでの再生が可能です。 マルチスクリーン・マルチマシン対応: シングル出力から大規模なマルチスクリーン、マルチマシン環境まで、ディスプレイレイアウトを管理・設定するためのツールを内蔵。 ネットワークインフラの構築: 同期オペレーターやハードウェアフレームロックを使用して、ネットワーク化されたインフラストラクチャを容易に構築できます。 多様なビデオ入出力: HD-SDIデバイスのネイティブサポート、NDI、Spout、Syphon、RTSPを介したストリーミング、および複数のオーディオ/ビデオソースの同時再生、ミキシング、トリガーをサポート。 ~ プロジェクションマッピング 多様なマッピングツール: 基本的な出力整形のための「Stoner」ツール、シームレスなプロジェクターブレンディングのための「ProjectorBlend」ツール。 2D/3Dマッピング: 2Dプロジェクションマッピングやマスキングのための「Kantan Mapper」、複雑な3Dマッピングのための「Camschnappr」ツール。 サードパーティソリューションとの連携: ViosoやScalable Displaysなどのサードパーティ自動マッピングソリューションをサポート。 高度な機能: リアルタイム3Dエンジンとの緊密な統合による事前視覚化、ドーム、VR、ステッチングなどのさまざまなプロジェクション形式をサポート。 ~ リアルタイム3Dとコンポジット リアルタイム3Dエンジン: プロシージャルジオメトリモデリング、FBX/USD形式のインポート、数千のジオメトリインスタンスの操作をGPUで高速処理。 高品質レンダリング: 物理ベースレンダリング（PBR）マテリアル、環境光、Substance Designerマテリアルのネイティブサポート、GLSLシェーダーやC++エフェクトによるカスタマイズ。 GPUアクセラレーション: GPUアクセラレーションによるコンポジットとレンダリング、高パフォーマンスなHD/4Kビデオ入出力。 幅広いフォーマット対応: さまざまなテクスチャタイプとピクセル形式、OpenColorIOによる業界標準の色補正、マッピング、ドーム、VR、ステッチングなどの多様なプロジェクション形式をサポート。 ~ VRサポート 既存機能とのシームレスな統合: TouchDesignerの全機能がVRツールとシームレスに統合され、VRコンテンツ開発を迅速化。 多様なVR体験: インスタレーションの事前視覚化、新しい視点からの過去の作品の再検討、インタラクティブな360度ムービーを含む新しいVR体験の作成。 マルチカメラ入力とステッチ: マルチカメラ入力とリアルタイムのマルチカメラステッチングのための「Stitcher」ツール。 デバイスサポート: HTC Vive、コントローラー、トラッカーのネイティブサポート、Oculus Riftのネイティブサポートと360度オーディオエフェクトのためのOculus Audio SDK。 VR内編集: 仮想エディターインターフェースを使用してVR環境内で直接プロジェクトを作成可能。 ~ ライティングとライブショー 多様なシステムとの通信: 照明機器、オーディオシステム、入出力デバイスなど、さまざまなライブショーシステムと通信可能。 照明制御: DMX、ArtNet、sACNを介して、ADB、MA Lighting、Martin Professionalなどの照明コンソールと双方向通信し、照明器具や機械的なステージデバイスを制御。 LEDとレーザー: オーディオ、ビデオ、画像をレーザーDACやコントローラーを使用してレーザーパターンやLEDパターンに変換。 音楽との統合: Ableton Liveとの統合、Ableton Sync EnvironmentおよびLinkテクノロジーによるタイミング同期。 幅広い入出力互換性: 双方向MIDIおよびOSC通信により、ほぼすべての入出力デバイスと互換性。 パフォーマートラッキング: ビデオカメラ、Kinect、BlackTrax、OptiTrackシステムを使用してパフォーマーを追跡。 安定性と拡張性: 何千ものLEDとチャンネルに対応し、プロジェクトで実証された安定性。 ~ 限定解像度版ライセンス 限定解像度版（Non-Commercial）は教育目的に限り利用可能です（商用利用不可） 教育用ライセンスはこちら},
  langid = {japanese},
  file = {C:\Users\mizuki\Zotero\storage\3SN2A5AV\touchdesigner.html}
}

@misc{USBfootpedal,
  title = {{{USB3連フットペダルスイッチ}} マウス操作対応 [{{RI-FP3BK}}] >> 有限会社 ルートアール ({{Route-R}}) パソコンパーツ・周辺機器の輸入卸売り、輸入代行、{{OEMの事なら全てルートアール}} ({{Route-R}})にお任せ下さい。},
  urldate = {2026-01-05},
  abstract = {パソコンパーツ・周辺機器の輸入卸売り・輸入代行・OEMの事なら全てお任せ下さい。},
  file = {C:\Users\mizuki\Zotero\storage\3IN5DADY\route-r.co.jp.html}
}

@article{VJingWiki,
  title = {{VJing}},
  year = 2025,
  month = dec,
  journal = {ウィキペディア},
  urldate = {2026-01-19},
  abstract = {VJing (pronounced: VEE-JAY-ing) is a broad designation for realtime visual performance. Characteristics of VJing are the creation or manipulation of imagery in realtime through technological mediation and for an audience, in synchronization to music. VJing often takes place at events such as concerts, nightclubs, music festivals and sometimes in combination with other performative arts. This results in a live multimedia performance that can include music, actors and dancers. The term VJing became popular in its association with MTV's Video Jockey but its origins date back to the New York club scene of the 1970s. In both situations VJing is the manipulation or selection of visuals, the same way DJing is a selection and manipulation of audio. One of the key elements in the practice of VJing is the realtime mix of content from a "library of media", on storage media such as VHS tapes or DVDs, video and still image files on computer hard drives, live camera input, or from computer generated visuals. In addition to the selection of media, VJing mostly implies realtime processing of the visual material. The term is also used to describe the performative use of generative software, although the word "becomes dubious ... since no video is being mixed".},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {japanese},
  annotation = {Page Version ID: 1325132486},
  file = {C:\Users\mizuki\Zotero\storage\9MYJYQ9D\VJing.html}
}

% !TEX root = _main.tex
% ========================================
% 卒業論文　本文
% ========================================
\section{はじめに}

%1.1
\subsection{背景}
音楽は，言葉を使わずに気持ちを表したり，他者と関わったりすることができる表現するための手段の一つであり，障がい支援の分野においても重要な役割を果たしている．特に，発達障がいのある児童生徒や身体障がいのある児童生徒にとっては，音や身体の動きを通した活動が自分の気持ちを表すきっかけとなることがある．
特に，発達障がいのある児童生徒や身体障がいのある児童生徒にとっては，音や身体の動きを通した活動が自分の気持ちを表すきっかけとなることがある．

本研究は，音楽と障がい者支援の関係性に関心を持ち，デジタル技術を用いた音楽表現の可能性について考えていたことから着想を得た．
その過程で，兵庫県立和田山特別支援学校において，デジタル技術を活用したイベントが企画されていることを知り，大学を通じてブース設置の依頼を受けた．
そこで，特別支援学校の児童生徒を対象とした音楽インタラクションシステムの作成および展示を行うこととなった．


%1.2
\subsection{目的}
本研究の目的は，大きく2つある．

　1つ目は，和田山特別支援学校に在籍する生徒児童を対象として，発達障がいや身体障がいといった多様な特性がある児童生徒でも，無理なく音楽と触れ合うことができるシステムを構築し，児童生徒が楽しみながら参加できる環境を提供することである．

２つ目は，WebカメラとPCを中心とした構成とし，一般的なソフトウェア開発環境や映像機器を用いることで，導入しやすい仕組みを示すことである．


%1.3

%\subsection{特徴}
%本研究の特徴は，特別支援学校での実践をもとに，WebカメラとPCのみを用いたインタラクションシステムを提案している点にある．
%複雑な操作を行うことなく，簡単な動きで音楽と関わることができるようにしている．

%また，実際の利用環境を想定した設計とすることで，様々な特性のある児童生徒が無理なく参加でき，音楽体験を楽しめる環境の構築を目指している．



%2
\section{調査}

%2.1
\subsection{特別支援教育におけるICT活用}
特別支援教育において，障がいの状態や特性，それに伴う学びにくさには大きな個人差があり，児童生徒一人ひとりに対応した支援が必要とされている．
文部科学省\cite{zotero-item-10345}においても，こうした背景があり，障がいの特性に応じたICT機器の活用や，理解や意思表示を支援するためのICT活用の重要性が示されている．

ICTは，学習内容をわかりやすく伝えるための補助としてだけではなく，愛堂生徒の意思表示や表現活動を支える手段としても活用されている．
特に，コミュニケーションに困難を感じやすい場合，音楽や映像，身体の動きなど非言語的な要素を取り入れることで，活動に参加しやすくなる場合がある．

本研究に先立ち，2025年10月3日に和田山特別支援学校を訪問し，校内の設備やICT活用の様子を見学した．
訪問時には遠隔操作ロボット「OriHime」を用いた実習の様子も見学し，生徒がロボットを介して他者と関わりながら活動している様子が見られた．

この見学を通して，ICTは児童生徒が社会とのかかわりを持つための一つのきっかけになるということが分かった．
また，この見学を行った経験は，本研究におけるシステム設計の方向性を考える上で参考になった．

%2.2
\subsection{発達障がいの特性と支援}
和田山特別支援学校には，身体障がいのある児童生徒や発達障がいのある児童生徒など，多様な特性を持つ児童生徒が在籍している．
本研究では，その中でも発達障がいのある児童生徒が多いという点を踏まえ，発達障がいの特性と支援について整理する．

発達障がいのある児童生徒は，感覚の受け取り方や情報の理解の仕方，コミュニケーションの取り方に様々な特徴を持っている．
そのため，言語的な説明を中心とした活動では，理解や参加が難しい場合もある．
一方で，音や動き，視覚的な変化といった感覚的な刺激に対して関心を示し，自分なりの方法で表現を行う児童生徒も多く見られる．
文部科学省の資料においても，発達障がいのある児童生徒に対しては，個々の特性に応じた教材やICT機器の工夫を通して，理解や意思表示を支援することの重要性が示されている．

また，活動の成果や正確さだけでなく，安心して参加できることや，活動そのものを楽しめることも大切な要素であるとされている．


%3
\section{対象者・設計方針}

%3.1
\subsection{対象者}
本研究の対象者は，和田山特別支援学校に在籍する児童生徒とする．
対象となる学年は小学部から高等部までとし，発達障がいのある児童生徒や，車いす利用者を含む身体障がいのある児童生徒など，多様な特性を有する利用者を想定している．

特別支援学校に在籍する児童生徒は，特性や身体状況に大きな個人差があり，活動への参加のしやすさも様々である．
そのため，本研究では特定の障がい種別に限定せず，多様な特性を持つ児童生徒が参加できることを前提とする．

%3.2
\subsection{和田山特別支援学校と参加したイベントについて}


%3.3
\subsection{利用環境の想定}
本研究で提案するシステムは，特別支援学校の体育館の一角での利用を想定している．
児童生徒が立位・座位のどちらであっても参加できるようにすることが条件であり，照明を落とした環境での利用を想定する．

%3.4
\subsection{設計方針}
本研究における設計方針の中心は，児童生徒が正しく操作することや成果を求めることよりも，楽しみながら活動に参加できることを重視する点である．
特別支援学校の教育現場では，活動への参加そのものが意味を持つ場合が多く，楽しさや安心感は活動を促す重要な要素であると考えられる．
そのため，本研究では，簡単に手を動かすだけで音楽と触れ合うことができるインタラクションにし，複雑な捜査や手順を必要としない設計を目指した．

また，このシステムはパソコンとWebカメラがあればだれでも利用できるようにするという点も重視している．

れらの設計方針は，事前に行った学校訪問やICT活用の見学を通して得た経験をもとに考えたものである．
見学では，児童生徒が安心して活動に参加し，楽しそうにしている様子が見られた．
こうした経験から，本研究では楽しさを大切にした設計が重要であると考えた．


%4
\section{システムについて}

%4.1
\subsection{システム概要}
本研究で制作したシステムは，Webカメラによって利用者の手の動きを認識し，その情報をもとに音や壁に映した映像が変化するインタラクションシステムである．

手の動きの認識には MediaPipe を使用し，取得した情報を Unity に送信することで，音楽再生や映像を制御している．

利用者は手を動かすだけで音楽や映像の変化を体験することができる．
そのため，身体的な制約のある児童生徒や，複雑な操作が難しい児童生徒であっても参加しやすい仕組みとなっている．

%4.2
\subsection{システム全体構成}
本研究で提案するシステムは，Webカメラ，PC，プロジェクター，スピーカーを用いて構成されている．
利用者の手の動きをWebカメラで認識させ，その動きに応じて音や映像が変化する仕組みとなっている．

%4.3
\subsection{入力から出力までの流れ}
本システムにおける入力から出力までの流れは，次のようになっている．

まず，Webカメラによって利用者の手の動きがリアルタイムで取得される．
上方向からのカメラでは，手の左右位置や奥行き方向の動きを捉え，横方向のカメラでは，手を押し込む，ここでは壁を手で押すような動きを捉えている．
これらの情報は，PC上で処理される．

処理された情報をもとに，音楽の再生や音量の変化，映像の変化が生成される．
これらの音と映像は，スピーカーとプロジェクターを通して利用者に示す．

%4.4
\subsection{画面構成}
基本的な画面構成は\figref{fig:basic}に示すとおりである。

\figref{fig:basic}の左に配置された雪だるまのイラストは，利用者が手を動かすと，その動きに追従するように画面上を移動する．
この雪だるまは，利用者の手の位置を視覚的に示す役割を持っており，利用者の動きを利用者自身にフィードバックするための要素である．

また，画面上にはキャラクターとして複数の動物イラストを配置している．
利用者が画面上の動物キャラクターの位置に手を移動させ，壁を押すような動作を行うと，その動物に対応する楽器の音色が再生される．
この際，対応する動物キャラクターは横揺れする動きを行い，その周囲に配置された音符のイラストが表示されたり消えたりする．

さらに，音が再生されている間は，画面中央に配置されたクリスマスツリーのオーナメントが明るくなったり暗くなったりすることで，音の再生状態を視覚的に示している．


\begin{figure}[tb]
    \includegraphics[width=\linewidth]{basic.png}
    \caption{画面の基本構成}
    \label{fig:basic}
\end{figure}



%5
\section{実装}

%5.1
\subsection{カメラ入力とMediaPipeによる座標取得}
利用者の手の動きを認識するために，本研究ではMediaPipeを用いて手の検出を行った．
MediaPipeは，Webカメラから入力された映像をもとに，人の手の関節点の座標をリアルタイムで推定することができるライブラリである．

本システムでは上方向から設置したカメラと横方向から設置したカメラの２つを使用し，それぞれのカメラに対してPythonプログラムを用意してカメラからの映像入力と手の座標取得を行った．

各カメラからの映像はOpenCVを用いて取得し，MediaPipeによる手検出の処理を行っている．
本研究では中指の先端に対応する関節点の座標を取得した．
中指の先端は，上方向からのカメラにも横方向からのカメラにも映りやすく，手の位置を安定して表しやすく，操作の基準点として扱いやすく適していると考え，採用した．

MediaPipeによって検出された手の座標は，0から１の範囲で正規化された値として取得される．
同時に複数の手を検出する設定は行わず，最初に検出されたひとつの手のみを対象として処理を行うようにした．

この後，取得した座標情報はPython プログラム内で次の処理段階である Unity への送信に利用される．

%5.2
\subsection{Pythonによる情報処理とUDP通信}
MediaPipeによって取得された中指先端の関節点の座標情報は，PythonプログラムからUDP通信でUnityへ送信している．
Python側では，フレームごとに手が検出されているかどうかを判断し，検出されている場合に中指先端の座標情報を送信データとしてまとめるようにした．

送信データには，手が検出されているかどうかの情報と中指先端の座標を０から１の範囲に正規化した座標値(x, y, z)の情報が含まれている．
これらをカンマ区切りの文字列としてUnityへ送信する．
通信方式は遅延を少なくするためにUDP通信を使用した．

Unity側では，UDP通信を行うためのスクリプトを作成してPythonからのデータを受信している．
受信データはUnityで保持され，後の音や映像の制御に利用される．

%5.3
\subsection{Unityにおける音・映像制御}
PythonからUDP通信によって送信された手の座標情報をUnity側で受信し，この情報をもとに音や映像の制御を行った．

音の制御に関しては，手の位置情報をもとに，再生される楽器の音色の切り替えや音量の変化を行っている．
基本の曲を「ジングルベル」とし，利用者が画面上の動物キャラクターの位置に手を移動させ，壁を押すような動作を行うと，対応する楽器の音色で曲が再生される仕組みを製作した．
例えば，うさぎのキャラクター付近に手を移動させ，壁を押す動きをすると，うさぎの弾いているピアノの音色に変化する．
このように，うさぎの範囲はピアノ，きつねの範囲はギター，
リスの範囲は弦楽器(ヴァイオリン，ヴィオラ，チェロ)，
小鳥の範囲は木管楽器(フルート，クラリネット)，
ハムスターの範囲は金管楽器(トランペット，ホルン)，
たぬきの範囲は打楽器(メロディを小さく声で流し，太鼓などの音が目立つようにした)の音が出るようにした．
これらはMuseScoreを使ってジングルベルの曲をそれぞれの楽器を使って楽譜を作成し，MuseScoreに収録されているそれぞれの楽器の音をWavファイルとして保存して使用している．
また，手の奥行き方向の位置情報を用いることで，手が壁に近づくほど音量が大きくなるようにした．

映像の制御に関しては，音が再生されている状態に応じて演出を行っている．
まず，出ている音に対応する動物キャラクターが横揺れする動きを行い，そのキャラクターの周囲に配置された音符のイラストが表示されたり消えたりする．
また，画面中央に配置されたクリスマスツリーのオーナメントが曲の再生中に明るくなったり暗くなったりすることで，音が鳴っている状態を示している．

%6
\section{実践}

%6.1
\subsection{当日準備}
本研究で制作したシステムは，2025年11月28日に実施された兵庫県立和田山特別支援学校で実施された「DXでつながるワトクの学び～UDゲーム交流会～」というイベントで展示を行った．
場所は学校の体育館の一角とし，壁面のプロジェクターを用いて映像を投影し，スピーカーから音を出力するようにした．

使用した機材，各機材の設置位置は\figref{fig:kizai}，\figref{fig:place}に示す．

\begin{figure}[tb]
    \includegraphics[width=\linewidth]{kizai.png}
    \caption{画面の基本構成}
    \label{fig:kizai}
\end{figure}

\begin{figure}[tb]
    \includegraphics[width=\linewidth]{place.png}
    \caption{画面の基本構成}
    \label{fig:place}
\end{figure}

%6.2
\subsection{体験の様子}
実践の中では，支援学校の児童生徒がシステムに興味をもち，比較的長い時間，場に留まって体験を続けてもらえる様子が見られた．
手を動かすことで音が鳴ることに気づき，手の動きを繰り返して音色の変化を試していて楽しみながら体験している児童生徒もいた．

また，身体を動かしにくい児童生徒も保護者や支援者と一緒に体験することで無理のない形で参加していた．
保護者が手を添えたり動かしたりすることで，判定しているのは保護者の手であっても，一緒に音や映像の変化を共有しているという体験の様子も確認できた．

一方で，システムの操作方法を言葉で説明することが難しい場面もあった．
手をゆっくり動かす，手のひらを上に向けるといった具体的な動作を伝える際には，言葉だけでなく実際に動きを示すなどの工夫が必要だった．

%6.3
\subsection{実践を通して見えた課題}
実践の様子から，本システムは，児童生徒が興味をもって体験に参加し，比較的長い時間遊び続ける場面も見られたことから，展示の一つとして一定の役割を果たしていたと考えられる．
会場の環境やシステムの都合で，音を出すことが難しい状況であったが，音が鳴った際に周囲の大人が「上手」「すごい」といった反応を示すことで，体験がより盛り上がる様子も確認できた．

一方で，技術的な課題も明らかになった．
まず，Webカメラによる手の認識は，会場の明るさに大きく影響を受けることが分かった．
暗すぎる環境では手の検出が不安定になり，明るすぎる環境では，プロジェクターで投影された映像が見えにくくなるという問題が生じた．

また，本システムでは２台のカメラを用いているため，設置や調整が複雑になり，音を出す，音色を切り替えるといった操作が分かりにくくなる場面もあった．
このことから，キーボード操作などによって同様の動作を再現できるデバッグ機能があると，動作確認や調整が行いやすくなると考えられる．



%7
\section{まとめと今後の課題}
本研究では，特別支援学校に在籍する児童生徒を対象として，WebカメラとPCを用いたインタラクションシステムの制作および実践を行った．
利用者の手の動きを認識し，その動きに応じて音や映像が変化する仕組みを構築することで，特別な道具などを使わず，簡単に手を動かすだけで音楽と関わることができる環境を目指した．

システムの実装においては，MediaPipe を用いた手の検出，Python による座標情報の処理および UDP 通信，Unity による音や映像の制御を組み合わせることで，
利用者の手の動きに対してリアルタイムに反応する音楽インタラクションを実現した．
また，動物キャラクターや音符，クリスマスツリーの演出など，
視覚的な要素を取り入れることで，音の再生状態や操作結果を分かりやすく示す工夫を行った．

実践では，児童生徒がシステムに興味を示し，
手を動かしながら音や映像の変化を体験する様子が観察された．
身体を動かしにくい児童生徒でも，保護者や支援者と一緒に体験することで，無理のない形で音楽活動に参加している様子が見られた．
一方で，操作方法の伝え方や展示環境の影響など，実践を通していくつかの課題も明らかになった．

今後の展望としては，まず，展示環境に左右されにくい手の検出手法や，より簡単な機材構成と機材の役割について考える必要がある．

さらに，複数人の手を同時に認識して合奏のような体験を行うことや，楽曲や音色の種類を切り替えられる仕組みを導入することで，
より多様な関わり方が可能な音楽体験へと発展させることができると考える．



\section{はじめに}

舞台演出などにおいて，照明は演奏表現を視覚的に拡張する重要な要素である.
しかし，従来の舞台照明は照明オペレーターによる手動操作に大きく依存しているという課題がある.

近年では，音響信号を用いて照明演出を自動化する研究\cite{tsukihigashi25}や楽曲の印象に基づいて照明を生成する研究\cite{kanno21}が報告されている．
また，演奏者の操作や身体動作と照明を連動させる試み\cite{asada20}も行われている．
しかし，これらの多くは音響情報または身体動作のいずれかに基づくものであり，両者を統合してリアルタイムに照明制御を行う手法は十分に検討されていない．

そこで本研究では，ヴァイオリン演奏に着目し、音響情報と身体動作を組み合わせ、リアルタイムで照明の制御を行うシステムの構築を目的とする。

\section{提案システム} 

本研究では、ヴァイオリンの演奏音から抽出した音響特徴量に基づいて照明を制御すると同時に、演奏者の運弓動作を照明の上下動作として直接反映するシステムを提案する．

具体的には、演奏音をマイクから取得し、1秒単位で音響特徴量を抽出する．
抽出する音響特徴量として、音量、スペクトル重心、スペクトルフラットネス、メル周波数ケプストラム係数(MFCC)など計10種類を用いる．
これらの特徴量から、学習済みの機械学習モデルを用いて，照明のRGB（Red：赤、Green：緑、Blue：青）の各成分，明るさ，点滅速度といった照明特徴量を推定する．
推定された照明特徴量をDMX信号に変換し，照明機器へ送信することで，リアルタイムに照明を制御する．

また，演奏者の右手首にスマートフォンを装着し，スマートフォンに搭載されたジャイロセンサから演奏者の運弓動作を取得する．
取得した運弓情報に基づき，弓の上下動作に応じて照明の上下動作（チルト）を直接制御することで，演奏者の身体動作を即時に照明へ反映する．

\section{機械学習モデル}

前述したように，ヴァイオリン演奏音から照明特徴量を推定するため，機械学習モデルを構築した．
モデルの入力には前述した10種類の音響特徴量，出力には前述した3種類の照明特徴量を用いた．

学習データには，実際のヴァイオリンソロ演奏映像(3種類)とMIDI データ(約600種類)を用いた．
また、機械学習モデルは，Random Forest 回帰モデルを採用した．

構築されたモデルは，システム稼働時に音響特徴量からリアルタイムで照明特徴量を推定するために使用される．

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/gurenge-play.png}
	\caption{『紅蓮華』実演中の照明変化の様子(左から「イントロ」、「Aメロ～Cメロ」、「サビ」、「サビ」)}
	\label{fig:gurenge-play}
\end{figure}

\section{実演と評価}

提案システムの有効性を確認するため，実際のヴァイオリン演奏を用いた実演を2回行った．
1回目は『君をのせて』,2回目は『紅蓮華』を演奏した．

実演は 2 回とも屋内（別場所）で行い，演奏者の周囲四方向に DMX 対応照明機器を 4 台設置した．照明機器は地面に配置し，床面から天井方向へ向けて照射される構成とした．これにより，四方から演奏者を照らす光環境を構築した．

両実演において，音量変化に応じて照明の明るさが連続的に変化し，楽曲の展開に伴って照明色が滑らかに遷移する様子が観察された．

さらに，スマートフォンのジャイロセンサから取得した運弓動作に基づき，弓の上下動作に同期して照明が上下動作することを確認した．

以上の結果から，演奏者が追加操作を行うことなく，音響情報および身体動作と連動したリアルタイム照明制御が可能であることを確認した．

\section{おわりに}

本研究では，ヴァイオリン演奏音の音響特徴量と演奏者の身体動作を統合的に用いたリアルタイム照明制御システムを提案した．
音響情報と身体動作の双方を照明演出に反映することで，演奏者主体の一体感のある照明演出の可能性を示した．

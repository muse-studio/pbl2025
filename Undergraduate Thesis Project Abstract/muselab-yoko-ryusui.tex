\section{はじめに}

舞台演出などにおいて，照明は演奏表現を視覚的に拡張する重要な要素である.
しかし，従来の舞台照明は照明オペレーターによる手動操作に大きく依存しているという課題がある.

近年では，音響信号を用いて照明演出を自動化する研究\cite{1}や楽曲の印象に基づいて照明を生成する研究\cite{2}が報告されている．
また，演奏者の操作や身体動作と照明を連動させる試み\cite{4}も行われている．
しかし，これらの多くは音響情報または身体動作のいずれかに基づくものであり，両者を統合してリアルタイムに照明制御を行う手法は十分に検討されていない．

そこで本研究では，ヴァイオリン演奏そのものを入力として，照明を自動かつリアルタイムに制御するシステムを提案する．
音響特徴量に基づく照明制御に加え，演奏者の運弓動作を直接照明の物理的動きに反映させることで，音楽表現と身体表現が一体となった照明演出の実現を目指す．

\section{提案システム} 

提案システムは，ヴァイオリン演奏音および演奏者の身体動作を入力とし，機械学習モデルによって推定された照明特徴量をDMX 信号として出力する構成である．

音響入力にはマイクを用い，演奏音から「スペクトル重心」，「スペクトル帯域幅」，「スペクトルコントラスト」，「スペクトルフラットネス」，「スペクトルロールオフ」，「ゼロ交差率」，「音量」，「メル周波数ケプストラム係数」，「クロマ特徴量」，「トーナルネットワーク」の合計10種類の音響特徴量を1秒単位で抽出する．
これらの特徴量を入力として，照明の「RGB値（Red：赤、Green：緑、Blue：青）の各成分」，「明るさ」，「点滅速度」を推定する回帰モデルを構築した．

また，スマートフォンのジャイロセンサを用いて演奏者の運弓動作を取得し，弓の上下動作に応じて照明の上下動作(チルト)を直接制御することで，演奏者の身体動作を即時に照明へ反映する．

\section{照明予測モデル}

本研究では，ヴァイオリン演奏音から照明特徴量を推定するため，機械学習による照明予測モデルを構築した．
モデルの入力には前述した10種類の音響特徴量，出力には照明の RGB 値，明るさ，点滅速度を用いた．

学習データの構築には，実際のヴァイオリン演奏映像に加え，MIDI データを用いた．
まず，演奏映像からヴァイオリン音のみを抽出した上で，音響特徴量を1 秒単位で算出した．

一方，映像フレームから背景照明領域を抽出した上で，RGB値,明るさおよび照明の点滅速度を抽出し，音響特徴量と照明特徴量の対応データを生成した．

さらに，データ量の補完および楽曲構造の多様性を確保するため，MIDI データを音声に変換し，同様の手順で音響特徴量を抽出した．

照明予測モデルには，学習後の推論が高速であるRandom Forest 回帰モデルを採用した．
学習済みモデルは，リアルタイムに入力される音響特徴量に対して照明特徴量を連続的に出力し，即時的な照明制御に利用される．

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/gurenge-play.png}
	\caption{『紅蓮華』実演中の照明変化の様子(左から「イントロ」、「Aメロ～Cメロ」、「サビ」、「サビ」)}
	\label{fig:gurenge-play}
\end{figure}

\section{実演と評価}

提案システムの有効性を確認するため，実際のヴァイオリン演奏を用いた実演を行った．

検証的実演として，映画音楽『君に乗せて』を演奏し，照明制御の挙動を確認した．
その結果，音量変化に応じて照明の明るさが連続的に変化し，フレーズの展開に伴って照明色が滑らかに遷移する様子が観察された．

また，公開実演として，楽曲『紅蓮華』を演奏し，リアルタイム制御の安定性を検証した．
その結果，強奏部では明度が上昇するなど，楽曲の盛り上がりに対応した照明変化が確認された(図1)．

さらに，両実演において，スマートフォンのジャイロセンサから取得した運弓動作に基づき，上げ弓・下げ弓に同期して照明が上下動作することを確認した．

以上の結果から，演奏者が追加操作を行うことなく，異なる性質の楽曲においても音響表現および身体表現と連動したリアルタイム照明制御が可能であることを確認した．

\section{おわりに}

本研究では，ヴァイオリン演奏音の音響特徴量と演奏者の身体動作を統合的に用いたリアルタイム照明制御システムを提案した．
音楽表現と身体表現の双方を照明演出に反映することで，演奏者主体の新しい照明演出の可能性を示した．

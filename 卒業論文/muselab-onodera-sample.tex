% !TEX root = _main.tex
% ========================================
% 卒業論文　本文
% ========================================
\section{はじめに}

小型のハードウェアシンセサイザー等電子楽器を複数個用いた演奏形態であるマシンライブは、ノブやフェーダー、ボタン(\figref{fig:TR-6S})を用いた微細かつ連続的なパラメータ制御、ならびに時間的に安定したトリガー入力を可能とする点で高い操作精度を有している。一方で、そのような入力インタフェースでは、インターフェース自体が小さいことや、それによって演奏者の動きも小さいものになるため、演奏行為自体が視覚的には単調に見えやすく、身体動作と音響変化との関係性が直感的に伝わりにくい。

筆者は、この身体動作と音響変化の関係性の伝わりにくさは、電子楽器演奏における表現の幅を制限している要因の一つであると考えており、その幅を広げることで、これまでの電子楽器演奏のクールな印象に加えて、新しい印象やイメージ、価値の持ったライブ体験を届けることが可能になると考えた。そして、電子楽器を用いた演奏がもっと視覚的に楽しめるようにするには、これまでの操作に加えて、身体動作と音響変化が一致して伝わる、つまり身体的ジェスチャーを用いた直感的な操作で音を操るといった音響的制御が大切であると考えた。

そこで本研究では、カメラベースのモーションキャプチャ技術であるMediaPipeを用い、演奏者の身体動作を直接MIDI制御へと変換するインタラクティブ演奏システムを提案する。これにより、演奏行動そのものを、視覚的・音響的な表現として捉え直し、電子楽器演奏における没入感の増幅を目指す。



%2
\section{電子楽器とその演奏について}

この章ではまず、マシンライブについての説明と筆者が考える改善点を示した後に、既存の電子楽器について述べた上で、目指すべきシステム構築の方針を定める。

\subsection{マシンライブ}
\subsubsection{マシンライブとは}
マシンライブは、一般的にハードウェアの電子楽器(ドラムマシンやシンセサイザー)を複数個用いたパフォーマンスのことを指す。現状では、詳しい定義は定められておらず、ハードウェアシンセの他にも、ソフトウェアシンセや生楽器の使用やDAW等による電子楽器の制御がなされることもある。そのため、本稿では、テクノ/ハウス/トランスといった音楽ジャンルがメインとなる、ハードウェアの電子楽器を中心としたライブパフォーマンスであると仮定する。

今回のような電子楽器を主体とした演奏では、演奏情報(ノート、タイミングなど)を記録・再生し、音源を鳴らして音楽を自動で演奏できるシーケンサーといった機器を使うことで、永続的に音源を流し続ける。その最中に演奏者が、電子楽器のつまみやフェーダーを動かすことによる音色パラメータの変更と、音色やシーケンスパターンの変更といった操作をリアルタイムで行う。これによって、曲に繊細な展開が生まれ、その展開を楽しむのがマシンライブの醍醐味となっている。

\subsubsection{マシンライブが有する問題・苦手分野}
マシンライブを行っている際に、操作の困難さや演出づくりが難しいと感じる部分がある。

その1つとして、マシンライブでよく使われる電子楽器特有の複雑な操作がある。マシンライブでは、基本シーケンサーに頼った演奏を行うことに加え、複数のシンセを用意することから、鍵盤のついていない小型のシンセサイザー(ガジェット系シンセともいう)などよく用いられるが、機器によっては、パラメータの変更に複雑な操作を要するものもある。例としては、Shiftボタンを押しながらのつまみの操作や、○○モードを選択したうえでの他の操作といったものである。

また、シーケンサーを回すことに頼った演奏のため、サンプラー等がなければ曲にアクセントをつけることが難しい。特に、曲中のセクションが変わる場面では、アクセントをつけることで、違和感のない曲の進みや、盛り上げを演出したいが、そのためには、シーケンスパターンの変更といったセクション変更の基本操作に加え、フィルターやエフェクトパラメータの変更や、パーカッションの追加が必要になる。短い時間でこのような多くの操作を行うのは、非常に難しく、演奏中の焦りにもつながってしまう。

そして、マシンライブはノブやフェーダー、ボタンを用いた入力方法によって、曲の展開を作り出すが、それらの入力インターフェース自体が小さいことや、それによって演奏者の動きも小さいものになるため、演奏行為と音響変化との関係性が視覚的かつ直感的には理解しづらい。筆者は、

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/TR-6S.png}
	\caption{ノブ・つまみ、フェーダー、ボタンの例}
	\label{fig:TR-6S}
\end{figure}

\subsection{シンセサイザー}
シンセサイザーとは、電子的に音を作り出し、合成したものを演奏できる楽器のことである。多くのパラメーターをいじることで、自分の好きなように音を作り演奏できるものと理解してもいいと思われる。一般的によく知られているシンセサイザーは、鍵盤がついているキーボードのような形をしているものだと思われるが、マシンライブでは、\figref{fig:synthesizer}のような小型のシンセサイザーがよく使われる。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/synthesizer.png}
	\caption{小型シンセサイザーの例(Roland S-1、KORG volca bass)}
	\label{fig:synthesizer}
\end{figure}

\subsection{MIDIコントローラー}
MIDIは、シンセサイザー等の電子楽器やコンピュータ間で演奏情報(音の高さ、長さ、強さなど)をやり取りするための共通規格である。そしてMIDIを使い、電子楽器やソフトウェアをコントロールするためのデバイスを、MIDIコントローラと呼ぶ(\figref{fig:MIDI_sample})。
主に、鍵盤やパッド、ノブ、フェーダー等のいずれかを組み合わせて構成されることが多く、これらと電子楽器等とでMIDIを用いた通信をすることによって、MIDIを用いた音の発音やパラメータの調整が可能になる。音楽制作における便利ツールとしてよく使用されるが、最近ではリアルタイムでの演奏にも使用される。


\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/MIDI_sample.png}
	\caption{MIDIコントローラーの例(AKAI MPK mini MK3、Novation Launchpad)}
	\label{fig:MIDI_sample}
\end{figure}

MIDIコントローラーの利点といえば、演奏者の操作とそれによって制御するMIDIの組み合わせを自分好みに作れる点であると考える。そのため、シンセサイザーのように、１つの入力インターフェイスで１つのパラメーターを制御しなくてもよく、１つの操作で複数のパラメータを制御することが可能である。


しかし、鍵盤やパッド、ノブ、フェーダー等を用いた入力方法では、やはり筆者の求める身体動作と音響変化の関係性は理解しづらい。

\subsection{インタラクティブ楽器}
電子楽器の分野では、鍵盤を弾くというような、一般的な入力方法のほかに、センサ技術やコンピューターの発展とともに、身体動作を音響制御に用いるインタラクティブ楽器が数多く提案されてきた。

その１つとして有名であるのが「テルミン」である(\figref{fig:terumin})。テルミンは1920年にロシアで生まれた電子楽器で、アンテナと手の間に生まれる電磁場の変化を感知して、音を制御する電子楽器である。そしてなんといっても1番の特徴は操作方法である。本体から伸びる2本のアンテナに手を近づけたり離したりすることで、音の高さと大きさの制御が可能であり、鍵盤のように音の場所が決まっていないため、手を小さく素早く振ることでビブラートを自由に表現できるというように、演奏者の身体動作が音響変化に反映される。このような楽器本体に触れずに、音を空中で操るといった演奏姿は、魔法使いのようにも感じられる。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/terumin.png}
	\caption{テルミン}
	\label{fig:terumin}
\end{figure}

また、日本でもYAMAHAが1995年に「Miburi」を開発・販売している。Miburi（ミブリ）は、指、手首、肘、肩、足にセンサーが付いたウェアを着た演奏者の身振り手振りといった身体動作を音楽の出力に関連付けることで、音を直接コントロールする電子楽器である。

そして、近年では、ArduinoやRaspberry Piといった、安価で応用用途の幅広いマイコンが開発され、一般ユーザーでもセンサ等を用いた、電子工作による新しい電子楽器の開発が比較的容易になった。

これらは、身体動作と音響変化が一致して伝わるといった点で、視覚的にも楽しめる演奏が可能な電子楽器であると考えられる。

しかし、これらの多くは専用デバイスの装着や特定環境への依存を前提としているほか、身体動作と音響変化が一致しても、演奏操作には一定の習熟が求められることから、ライブパフォーマンスへの導入には依然として制約が存在する。

\subsection{研究の方針}
このような既存の電子楽器の特徴から、本システムでは以下のような要素を持つように方針を定めた。
\begin{enumerate}
	\item \textbf{容易な動作ながらも多くのMIDIを制御できるシステム}　\\
		まずMIDIで小型ハードウェアシンセサイザーを制御することで、前述した小型シンセ特有の複雑な操作を1つの入力インターフェースによる操作で完結させる。
		また、MIDIコントローラーのように、１つの操作で複数のパラメーターを制御でき、その制御する入力インターフェースとMIDIの組み合わせを、自由に作れるようにする。

		これによって、マシンライブの苦手分野であった、小型シンセ特有の複雑な操作と、突発的なアクセント付けの操作の難しさといった問題を解決する。
	\item \textbf{身体動作と音響変化の関係性が理解できる動きを用いたシステム。}　\\
	    身体動作と音響変化の関係性が理解できる操作で電子楽器を制御するために、私はMediaPipeによって身体ジェスチャーをリアルタイムに検出することで、ジェスチャーでMIDIを制御する方法を考えた。
		ジェスチャーであれば、ある程度の動きを確認できる演奏操作ができるとともに、複数の電子楽器による多くの入力インターフェースを用いることによる、操作の難しさと焦りが出てしまうといった問題も、直感的な操作で解決できないかと考えたからである。

		そこで本システムでは、ジェスチャーをMIDI制御のための入力インターフェースとすることで、身体動作と音響変化の関係性理解と、マシンライブにおける困難な操作容易化を目指す。
	\item \textbf{容易な導入が可能なシステム}　\\
		既存の電子楽器にも、身体動作と音響変化が一致して伝わり、視覚的にも楽しめる演奏が可能なものは存在したが、専用デバイスの装着や特定環境への依存を前提としていることや、演奏操作には一定の習熟が求められることから、容易に導入できるものではなかった。

		そこで本システムでは、MediaPipeとMaxを用いることで、パソコンとカメラがあれば導入ができ、操作も自然に行えるようなジェスチャーを軸とすることで、パフォーマンスにおいて容易に導入が可能なシステムの構築を目指す。
\end{enumerate}　\\

これらの要素を含めたシステムを構築することで、視覚的な楽しさを追加するほか、従来の演奏方法の難点を解決することで、マシンライブにおける没入感増加を目指す。

%3
\section{システム設計}
ユーザーのハンドジェスチャーに対する、電子楽器演奏における没入感の増幅と、既存の枠組みを超えた新たな印象および価値の創出の有効性を検証するため、ハンドジェスチャーによって直感的なMIDI制御が可能なエンタテイメントシステムを構築した。
ユーザは片方どちらかの手全体がWebカメラに映る状態を取り、システムに用意されているジェスチャーを行うと、各ジェスチャに対応したMIDI情報がシンセサイザー等のMIDI対応機器に送られ、ユーザーは直感的な操作による演奏を楽しむことができる。
\subsection{設計方針}
2.5節の研究の方針をもとに、本研究では入力インターフェースであるジェスチャーと


\subsection{使用ツール}
本システムは、リアルタイムな身体動作検出のために「MediaPipe」を使用している。また、これによって得た値のMIDIとして扱える値への変換と、MIDI送信のための設定、ジェスチャーと実装した機能のパッチングに「Max」を使用している。

これらのツールの選択理由と使用目的について詳しく述べる。

\subsubsection{MediaPipe}
手指の骨格情報と位置、動きの検出のため、MediaPipeを使用することにした。MediaPipeは、画像や動画データをリアルタイムで処理し、顔認識、姿勢推定、手の検出といった身体動作検出が可能な、Google社が提供するオープンソース機械学習フレームワークである。\figref{fig:MediaPipe_open}は、MediaPipeでの手情報取得の例である。

PCへのカメラ映像入力のみで身体動作検出が可能という導入の容易さと、動作検出の速さがライブパフォーマンスで使用できるレベルだと感じたため、導入に至った。

なお、本研究ではGitHub上で公開されているRob Ramirezのソースコードであるhands-gesture-recognizer.maxpatを基にシステムを構築した。当該ソースコードは、指の関節などを表す21個の特徴点\figref{fig:hand-landmarks}のカメラ画角内の位置座標(x軸、y軸、z軸)の取得と、7種類の一般的なハンドサイン(\tabref{tab:handsign})の自動認識を目的とした実装であり、本研究の目的に合わせて一部の処理を改変・拡張して使用した。


\begin{figure}[tb]
	\centering
	\includegraphics[width=0.5\hsize]{../fig/MediaPipe_open.png}
	\caption{MediaPipeでの手情報取得の例}
	\label{fig:MediaPipe_open}
\end{figure}

\begin{table}[tb]
	\centering
	\small
	\begin{tabular}{c}
		\hline
		\hline
		ハンドサイン名 \\
		\hline
		Closed fist  \\
		Open palm \\
		Pointing up \\
		Thumbs down \\
		Thumbs up \\
		Victory \\
		ILoveYou \\
		\hline
		\hline
	\end{tabular}
	\caption{自動認識できるハンドサイン}\label{tab:handsign}
\end{table}

本システムでは、WebカメラやPC内蔵カメラを使用してユーザーの手を撮影し、得られる手指の関節21箇所の位置情報と、ハンドサインの自動認識結果を映像から取得する。
そして、取得したx座標、y座標は、ジェスチャー判定のための計算値として、ハンドサインはシステムにおけるトリガーのような操作のために使用する。
なお、本システムではカメラ画角内の左から右に向かって0→1、上から下に向かって0→1のx、yそれぞれの座標を取得できる。


\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/hand-landmarks.png}
	\caption{位置情報を取得する21箇所}
	\label{fig:hand-landmarks}
\end{figure}


\subsubsection{Max}
本システムは、システム構築環境として、ビジュアルプログラミング環境であるMax(Cycling ’74)を用いた。Maxは、音響信号処理や映像処理をリアルタイムに統合して扱うことが可能な開発環境である。
ユーザは、それぞれ特定の処理を行うオブジェクトをパッチャ上に配置し、それらを接続することで処理の流れを構築する。今回は、外部入力デバイスから取得した情報を音楽的制御信号へ変換する処理や構造を直感的に設計できることに加え、視覚的に把握することができるといった点から、Maxを使用してシステム構築をすることにした。

\subsection{MIDI}
本システムでは、MIDIを用いて電子楽器を制御する。

MIDIは、シンセサイザー等の電子楽器やコンピュータ間で演奏情報(音の高さ、長さ、強さなど)をやり取りするための共通規格である。MDIで扱うデータ(メッセージ)には、いくつかの種類が存在するが、本システムでは主にノートオン/オフ・ノートナンバー、コントロールチェンジ(CC)の3つのメッセージを扱う。それぞれのメッセージについて詳しく説明する。

\subsubsection{ノートオン/オフ・ノートナンバー}
ノートオンは鍵盤を押したときに送られる音を鳴らす信号、ノートオフは鍵盤を離したときに送られる音を止める信号のことである。また、ノートナンバーは、音の高さを0から127までの数字で表現したものである。これらのメッセージを組み合わせることで、どの高さの音を鳴らす、止めるといった制御が可能になる。

\subsubsection{コントロールチェンジ(CC)}
コントロールチェンジ(以降CCと呼ぶ)は、音量、定位(パン)、音色、モジュレーションなど、音楽的な表現やパラメーターを制御するためのMIDI信号であり、シンセサイザー等のノブやフェーダーの制御量を0〜127の数値として送信し、音色やエフェクトなどをリアルタイムに制御できる。

CCは、どのパラメーターを制御するかを示す0〜127の番号であるコントロールナンバー(CCナンバー)と、そのパラメーターの制御値0〜127の主に２つの要素で構成される\figref{fig:cc_logic}。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/cc_logic.png}
	\caption{MIDI CCの構成}
	\label{fig:cc_logic}
\end{figure}

\subsection{実装ジェスチャー}
システムを制作する上で、筆者は既存の電子楽器やMIDIコントローラーにおけるパッドやボタン的な役割に加え、システム内の動作のきっかけ的な役割を持った、単発的な信号を送信する「トリガージェスチャー」と、
ノブやフェーダー的な役割を持った、連続的な信号を送信する「コントロールジェスチャー」の2種類のジェスチャーが必要だと考えた。

そのため、本システムでは\tabref{tab:gestures}のジェスチャーを実装した。
それぞれのジェスチャーについては4章にて詳しく説明する。

\begin{table}[tb]
	\centering
	\small
	\begin{tabular}{c|c}
		\hline
		\hline
		トリガージェスチャー  & コントロールジェスチャー  \\
		\hline
		\hline
		ハンドサイン & カメラからの距離  \\
		(Closed Fist,Pointing Up, & 手の開き具合  \\
		Victory,ILoveYou)  & ノブを回す動作 \\
		スワイプ  &  \\
		\hline
	\end{tabular}
	\caption{実装ハンドジェスチャー一覧}\label{tab:gestures}
\end{table}

\subsection{想定する使用環境}
本システムは\figref{fig:siyoukankyou}のように、複数個のシンセサイザーが並んだマシンライブ環境下に設置する、便利なMIDIツールとしての使用を想定している。そこでユーザーは、カメラに向けて実装されているジェスチャーを取ることで、MIDIの制御が行える。また、このシステムを使用する際に、片方の手はシンセサイザーの操作、もう片方をジェスチャー操作という形を取れるようにするため、片手操作を軸としたシステム構築を行なった。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/siyoukankyou.png}
	\caption{想定する使用環境}
	\label{fig:siyoukankyou}
\end{figure}

\subsection{システム処理の流れ}

これらの設計方針から、\figref{fig:logic_system}のような流れのシステムを構築した。まず、MediaPipeによって得られる情報でジェスチャーを認識し、そのジェスチャーを取った際に出力される値をMIDI送信で使える形に変換する。
そして、どのジェスチャーによる値をどのMIDI機器へ送信し、どのような変化させるかというパッチング設定を行うことで、ハンドジェスチャーによる直感的なMIDI制御が可能になる。



\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/logic_system.png}
	\caption{システム内部処理の流れ}
	\label{fig:logic_system}
\end{figure}

%4
\section{ハンドジェスチャーによるMIDIの制御}

本章では、本システムで実装したジェスチャーや機能、内部処理の流れとユーザーが設定する項目について述べる。

\subsection{ユーザーが取るジェスチャー}


実装されているジェスチャーと信号送信の種類は、以下のようである。

\begin{itemize}
	\item ハンドサイン(単発)　\\
	(Closed Fist,Pointing Up,Victory,ILoveYou)
	
	\item カメラからの距離(連続)
	\item 手の開き具合(連続)
	\item ノブを回す動作(連続)
	\item スワイプ(単発)
\end{itemize}

これらのジェスチャー１つ１つについて、詳しく説明する。

\subsection{ハンドサイン}
本システムでは、Closed Fist、Pointing Up、Victory、ILoveYouの4種類のハンドサインを自動認識し、これらのジェスチャーを取ったらMIDI情報を送信するといった単発的なトリガーとして使用することができる(自動認識の様子)。また、これらのジェスチャーを取ったときと、ジェスチャーをやめた時の２回、信号を送ることが可能である。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/hand-sign.png}
	\caption{4種類のハンドサイン}
	\label{fig:hand-sign}
\end{figure}


\subsection{カメラからの距離}
本システムでは、カメラと手の距離に応じて、\figref{fig:dis_ba}のように連続的に送信値を変化させることができる。

カメラからどれだけ離れているかの測定には、MediaPipeによって得られた手首と小指の付け根の位置座標間の距離を使用している。つまり、距離が短くなる＝カメラから手が離れているとなるわけである。

今回は、それぞれの座標間の距離の中で、カメラからの距離を変えずに様々なハンドジェスチャーを取った際に、距離の変化が少なく、測定箇所が他の指で隠れるようなことも少ないため、この座標間の距離を使用した。また、MediaPipeはz軸座標の取得もできるが、測定誤差が大きいため、本システムでの使用は断念した。

座標間の距離は、手首と小指の付け根それぞれのx軸、y軸座標を、Max内での三平方の定理の計算に用いることで出力している。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/dis_ba.png}
	\caption{カメラからの距離による値の変化}
	\label{fig:dis_ba}
\end{figure}

\subsection{手の開き具合}
本システムでは、手の開き具合に応じて、\figref{fig:close_ba}のように連続的に送信値を変化させることができる。

開き具合の測定には、手首と中指先端の位置座標間の距離を使用しており、手首と中指先端それぞれのx軸、y軸座標を、Max内での三平方の定理の計算に用いることで距離を出力している。

また、この出力された値は、単にカメラ画角内の２座標間の距離によるもので、この状態ではカメラと手の距離によっても出力される値は変化してしまう。今回は手の開き具合のみの値を出力したいため、「手首と中指先端間の距離÷カメラからの距離」の計算をすることで、この問題を解決し、ユーザーの手がカメラ画角内のどの位置にいても、出力値が同じ値の幅になるようにした。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/close_ba.png}
	\caption{手の開き具合による値の変化}
	\label{fig:close_ba}
\end{figure}

\subsection{ノブを回す動作}
本システムでは、\figref{fig:tsumami_ba}のようにシンセサイザー等についているノブ・つまみを回すようなジェスチャーをカメラに向けて取ることで、連続的に送信値を変化させることができる。

送信値は、親指先端と人差し指先端の２点間の角度を元に変化する。本システムでは、2点のx座標、y座標それぞれの座標差を使い、アークタンジェント2関数でラジアン値を得て、それを度数に変換することで、角度を出力している。以下はその式である。
\[
\begin{array}{c}
{\displaystyle
\theta_{\mathrm{deg}} =
\arctan\!\left(\frac{f_1}{f_2}\right)\times \frac{180}{\pi}
} \\
{\small
(f_1:\, y\text{座標差},\; f_2:\, x\text{座標差})
}
\end{array}
\]

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/tsumami_ba.png}
	\caption{ノブを回す動作による値の変化}
	\label{fig:tsumami_ba}
\end{figure}

\subsection{スワイプ}
単発的な信号を送るジェスチャーが必要だと感じ、どのようなジェスチャーが適しているか考えた。その際に、ギターやハープのように何かを弾く動作は、トリガーとしての役割を持つジェスチャーとして適していることに加え、動作と音響変化の関係性も理解しやすいのではないかと考えた。

このことから、本システムではカメラ画角内で、何かを弾いているように見える、つまり上下左右に指先を素早く振るジェスチャーをトリガーとして、単発的な値の送信に使用できるようにした。

このジェスチャーでは、下から上、上から下、右から左、左から右の４方向の振る動作に対応しており、\tabref{tab:swipe_gate}のように150msのうちに、中指先端の座標を用いて算出された移動距離が距離閾値を超えることで、単発的な信号(bang)を出力する仕組みとなっている。

\begin{table}[tb]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c|c|c}
\hline
\hline
\textbf{スワイプ方向} & \textbf{時間 [ms]} & \textbf{距離} \\ 
\hline
\hline
左から右(→) & \multirow{4}{*}{150} & $0.15 < x_t - x_{t-1}$ \\ \cline{1-1}\cline{3-3}
右から左(←) &  & $-0.15 > x_t - x_{t-1}$ \\ \cline{1-1}\cline{3-3}
上から下(↓) &  & $0.2 < y_t - y_{t-1}$ \\ \cline{1-1}\cline{3-3}
下から上(↑) &  & $-0.2 > y_t - y_{t-1}$ \\ \hline
\end{tabular}
\vspace{0.5em}

{\footnotesize
$x_t$：今の左右位置座標，
$x_{t-1}$：直前(150ms前)の左右位置座標，\\
$y_t$：今の上下位置座標，
$y_{t-1}$：直前(150ms前)の上下位置座標
}
\caption{スワイプ判定条件}\label{tab:swipe_gate}


\end{table}




%5
\section{実装}



\subsection{基本設定画面}
ユーザーは、Maxでカメラ映像設定やそれぞれの値出力パターンに対応するジェスチャーの選択、MIDI送信のための設定などを行う必要がある。

そして、図○は実際の設定画面である。これらの設定を行うことで、ジェスチャーを取った際に適切な電子楽器へのMIDI送信が実行され、ユーザー好みの直感的な操作による演奏が可能になる。

\subsubsection{セクション説明}

\begin{enumerate}
	\item \textbf{カメラ映像設定}　\\
	    このセクションでは、入力映像とMediaPipeにおける設定を行う。
	\item \textbf{全体設定}　\\
	    このセクションでは、システム全体
	\item \textbf{ジェスチャー設定(トリガー・コントロール)}　\\
	    このセクションでは、単発的な値の送信(トリガー)と連続的な値の送信(コントロール)のそれぞれで、どのような動きの値をどの電子機器へどのようなジェスチャーで送信するのか決めるため、ジェスチャーの選択やMIDI送信における設定を行う。
\end{enumerate}


\subsubsection{ジェスチャーアイコン説明}
ジェスチャー設定セクションにて、使用するジェスチャーを選択するためのアイコンを用意しているため、これについての説明を行う。

このアイコンはスイッチの役割を持っており、クリックすることでアイコンの縁が光り、オンの状態になったことを示す。つまり、オンにしたジェスチャーによって値の制御を行うことを示す。

\begin{enumerate}
	\item \textbf{ハンドサインアイコン}　\\
	    ハンドサイン(Closed Fist,Pointing Up,Victory,ILoveYou)が制御ジェスチャーとして選択されるアイコン。トリガージェスチャーとして扱う場合は、オフ(指定のジェスチャーを取っていない)、オン(ジェスチャーを取った時)、オン(ジェスチャーをやめた時)の3段階のスイッチとして機能し、コントロールジェスチャーとして扱う場合は、オフ(指定のジェスチャーを取っていない)、オン(ジェスチャーを取っている)の2段階のスイッチとして機能する。
	\item \textbf{スワイプアイコン}　\\
	    このセクションでは、システム全体
	\item \textbf{距離アイコン}　\\
	    このセクションでは、単発的な値の送信(トリガー)と連続的な値の送信(コントロール)のそれぞれで、どのような動きの値をどの電子機器へどのようなジェスチャーで送信するのか決めるため、ジェスチャーの選択やMIDI送信における設定を行う。
	\item \textbf{開閉アイコン}　\\

	\item \textbf{ノブアイコン}　\\
\end{enumerate}

\subsubsection{基本的な実行の流れ}



\subsection{基本姿勢}

今回はシステムの仕様上、手掌面が撮像デバイスに対して正面を向いている姿勢を基本姿勢とする。ユーザーはこの姿勢からハンドジェスチャーを取ることで、トリガーとしての役割や、MIDI送信値の連続的な変化を、適切に実行することができる。


\subsection{MIDI送信設定}
シンセサイザー等へMIDIを送信するためには、\figref{fig:MIDI-set}のようにMIDI送信先、ノートナンバー・CCナンバー、MIDIチャンネル、MIDI CC範囲の４種類の項目をユーザが設定する必要がある。それぞれの項目について詳しく説明する。

\begin{figure}[tb]
	\centering
	{\setlength{\fboxsep}{0pt}
	 \setlength{\fboxrule}{0.5pt}
	 \fcolorbox{gray}{white}{%
	   \includegraphics[width=0.8\linewidth]{../fig/MIDI-set.png}
	 }}
	\caption{MIDI送信設定画面}
	\label{fig:MIDI-set}
\end{figure}


\subsubsection{MIDI送信先}
この項目では、MIDI情報の送信先を決める。Maxの起動時またはMIDI機器の検索ボタンを押した際に、PCにつながっているシンセサイザー等のMIDI機器がポップアップメニューに表示され、選択したMIDI機器に情報が送信される。

\subsubsection{CCナンバー・ノートナンバー}
トリガージェスチャーを扱う際に設定が必要になる項目であり、単発的に送るCCナンバー

\subsubsection{MIDIチャンネル}
MIDI機器によっては、送信先の設定のほかにも、MIDIチャンネルを設定する必要がある。

MIDIチャンネルは、1本のMIDIケーブルで複数の楽器(パート)の演奏情報を区別して送受信するための1〜16の番号で、各パートにチャンネルを割り当てることで、異なる楽器を同時にコントロールすることができる。

本システムでも、1〜16の番号を指定することで、1つのPCで複数のMIDI機器を使い分けることが可能である。

\subsubsection{MIDI CC範囲}
MIDIコントロールチェンジを使ってシンセサイザー等MIDI機器を制御する際に、どの値の範囲のみジェスチャーで変化させるかを設定することができる。

\figref{fig:CC-rangeAB}は設定つまみである。このつまみ両端の白と青の丸を動かすことで範囲を設定することができる。この範囲は\figref{fig:CC-range}のように、MIDIで制御するシンセサイザーのつまみ等のパラメータと模しているものになっており、どの範囲のみパラーメータを変化させるかが視覚的に理解しやすく設定できる。

つまり、カメラからの距離でシンセサイザーを操る場合、\figref{fig:CC-rangeAB}のAの時は、カメラと手の距離が1番短い場合にCC値30を出力し、1番長い場合にCC値100を出力する。

また\figref{fig:CC-rangeAB}のBのように、両端の白と青の丸が逆転している場合は、先ほどと逆方向に値が変化する。つまり、カメラと手の距離が1番短い場合にCC値100を出力し、1番長い場合にCC値30を出力する。

\begin{figure}[tb]
	\centering
	\includegraphics[width=0.8\hsize]{../fig/CC-rangeAB.png}
	\caption{CC範囲設定つまみ}
	\label{fig:CC-rangeAB}
\end{figure}

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/CC-range.png}
	\caption{CC範囲設定の詳細}
	\label{fig:CC-range}
\end{figure}


\subsection{トリガージェスチャーとコントロールジェスチャー}
マシンライブの課題である、
単発的な操作、信号送信を担う「トリガージェスチャー」と、連続的な操作、信号送信を担う「コントロールジェスチャー」の２種類のジェスチャーを用意した。
このシステムには、単発動作をトリガーに、指定した単発的なMIDI情報を電子楽器等へ送信する［単発モード］と 、細かな手指の動きによる連続的な値の変化によってMIDI CCのコントロールが可能な［連続］の２つのモードが存在する。



\subsection{トリガージェスチャー設定}

指定したCCナンバーにおける送信値とノートナンバー、そしてこれら２つのどちらかを時間的な値変化で制御するための単発的な信号を送るジェスチャーについて説明する。



\subsubsection{対応ジェスチャー}
この
\begin{itemize}
	\item ハンドサイン　\\
	(Closed Fist,Pointing Up,Victory,ILoveYou)
	\item スワイプ(上下左右)
\end{itemize}



\subsubsection{MIDI CC機能}
選択したジェスチャーを取ることで、指定したCCナンバー

\subsubsection{ピッチ機能}
選択したジェスチャーを取ることで、指定したノートナンバーが電子楽器に送られ、そのノートナンバーに対応した高さの単音が出力される機能である。
\subsubsection{タイム機能}

トリガージェスチャーによって、単発的な信号が送られると、ユーザーが指定した時間、変化量に従って、値が送られる。またこの機能はMIDI CCとピッチ両方の変化に対応しており、「送信MIDI選択」にてどちらを変化させるか選択できる。

\figref{fig:time}が、Maxにおけるタイム機能の設定画面である。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/time.png}
	\caption{タイム機能設定画面}
	\label{fig:time}
\end{figure}

\begin{enumerate}
	\item \textbf{使用ジェスチャー選択}　\\
	    使用したいジェスチャーのアイコンをクリックすることで、そのジェスチャーをトリガーに送信値の時間的変化が開始される。
		
		またハンドサインは、オフ、オン(ジェスチャーを取った時)、オン(ジェスチャーをやめた時)の3段階に分けて選択ができる。
	\item \textbf{基本設定}　\\
	    この機能の時間的情報を決める。
		\begin{itemize}
			\item \textbf{BPM}　\\
        		演奏する曲のBPMを入力する。
    		\item \textbf{長さ(拍)}　\\
        		設定したBPMに沿った拍数を選択する。これによってこの機能の最大の長さを設定できる。
			\item \textbf{長さ(秒)}　\\
				秒数を入力することで、この機能の最大の長さを設定できる。拍数ではなく、秒数で値が変化する時間を設定したい場合は、こちらを入力する。
		\end{itemize}
	\item \textbf{MIDI設定}　\\
	    この機能のMIDIに関係する情報を決める。
		\begin{itemize}
			\item \textbf{送信MIDI選択}　\\
        		「コントロールチェンジ」=MIDI CC、「ノートオン・オフ」=ピッチの、どちらをこの機能で制御するのかを選択する。
    		\item \textbf{MIDI送信先}　\\
        		値を送信するMIDI機器を選択する。
			\item \textbf{CCナンバー}　\\
				「送信MIDI選択」で「コントロールチェンジ」を選択した場合に、制御したいCCナンバーを入力する。
			\item \textbf{MIDIチャンネル}　\\
				送信先のMIDIチャンネルを入力する。
		\end{itemize}
	\item \textbf{変化量設定}　\\
	    この機能の送信する値の変化の流れを設定する。
		\begin{itemize}
			\item \textbf{functionオブジェクト}　\\
        		縦軸が送信値、横軸が時間の値の時間的変化を、点とそれをつなぐ直線・曲線で作成するオブジェクト。オブジェクトの左から右に向かって値が変化する。
    		\item \textbf{テスト用ボタン}　\\
        		値を送信するMIDI機器を選択する。
			\item \textbf{プリセット}　\\
				作成した値の時間的変化を保存、呼び出しする。
			\item \textbf{全消去}　\\
				functionオブジェクト上の点と線を全て削除する。
		\end{itemize}
\end{enumerate}

\subsection{コントロールジェスチャー設定}
指定したMIDI CCとピッチ範囲で、連続的な値変化
指定したCCナンバーにおける送信値とノートナンバー、そしてこれら２つのどちらかを時間的な値変化で制御するための単発的な信号を送るジェスチャーについて説明する。
\subsubsection{対応ジェスチャー}

\subsubsection{MIDI CC機能}
操作値が大きくなればなるほど、MIDI CC範囲に従って、送信値が変化する。カメラ画角内で手が認識されなくなった場合、送信値はMIDI CC範囲の最低値(白丸の値)に戻る。

また、ハンドサインアイコンを選択した場合は、選択したハンドサインを取った状態でカメラからの距離を変えることで、操作値が変化するようになり、ハンドサインを取ってない場合は、値の変化は起きない。カメラ画角内で手が認識されなくなった、もしくはハンドサインを取るのをやめた場合、送信値はMIDI CC範囲の最低値(白丸の値)に戻る。

\subsubsection{ピッチ機能}
操作値に従って、

操作値が大きくなればなるほど、スケールにしたがって高い音が出る、モノフォニック・シンセサイザーのように使用することができる機能である。スケールとルート音、オクターブ範囲の設定によって、発音される音の高さと範囲が決められる。カメラ画角内で手が認識されなくなった場合は音が止まる。

また、ハンドサインアイコンを選択した場合は、選択したハンドサインを取った状態でカメラからの距離を変えることで、操作値が変化するようになり、スケールに沿って音が発音される。ハンドサインを取ってない場合は、値の変化や音の発音は起きない。カメラ画角内で手が認識されなくなった、もしくはハンドサインを取るのをやめた場合は音が止まる。

実装しているスケールと、入力できるルート音のMIDIノート番号範囲と、オクターブ範囲は\tabref{tab:scale}のとおりである。

\begin{table}[tb]
	\centering
	\small
	\caption{スケール、ルート音、オクターブ範囲}\label{tab:scale}
	\begin{tabular}{c|p{3cm}}
		\hline
		\hline
		変更する値       & 選択肢・値の範囲         \\
		\hline
		\hline
		スケール  & major minor pentatonic minor-pentatonic harmonic-minor dorian mixolydian lydian phrygian locrian  \\
		\hline
		ルート音のMIDIノート番号  &  0-127  \\
		\hline
		オクターブ範囲  & 1-3 \\
		\hline
		\hline
	\end{tabular}
\end{table}

\subsection{機能説明}

\subsubsection{スムージング機能}
MediaPipeから得られる連続値を扱う際に、測定誤差や環境要因によって、急激な値変化が起きてしまうことが度々ある。これは、結果的に出力される音の音切れや不自然な音色変化につながってしまうため、どうにか対処する必要があった。そこで、本システムでは、値の時間的変化を平滑化するスムージング機能を導入することで、急激な値変化の抑制と、より自然かつ安定したMIDI制御を実現した。

この機能は、Max内のlineオブジェクトを使用することで成り立っている。今回は、「100msかけて前の値から新しい値へスムーズに変化」とすることで、スムージングを可能にしている。



\label{sec:contents}

\section{実演}
今回構築したハンドジェスチャーによるMIDI制御システムについて、実際の演奏環境における有効性を確かめるため、実演とそれに伴う評価を行なった。

\subsection{実演環境}
研究室内にて、ゼミ生6名を対象に構築したシステムを用いたマシンライブを実施した。使用機材は、小型シンセサイザー2台とPCである。また、カメラはPC内蔵カメラを用いた。
使用機材の配置は\figref{fig:live_set}のとおりである。今回は、主に左手でシンセサイザーの操作を行い、右手でジェスチャーを取った。

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/live_set.png}
	\caption{使用機材の配置}
	\label{fig:live_set}
\end{figure}

\subsection{実演内容}
実演するにあたって、ダンスミュージックの要素を持った4分弱の曲を作成した。


\begin{table}[tb]
	\centering
	\small
	\begin{tabular}{c|p{3cm}}
		\hline
		\hline
		使用ジェスチャー & 対応する音・パラメータの変化 \\
		\hline
		\hline
		スケール  & major minor pentatonic minor-pentatonic harmonic-minor dorian mixolydian lydian phrygian locrian  \\
		\hline
		ルート音のMIDIノート番号  &  0-127  \\
		\hline
		オクターブ範囲  & 1-3 \\
		\hline
		\hline
	\end{tabular}
	\caption{実演で使用したジェスチャーと対応する音響的変化}\label{tab:scale}
\end{table}

\begin{figure}[tb]
	\centering
	\includegraphics[width=\hsize]{../fig/live_swipe.jpg}
	\caption{実演の様子}
	\label{fig:live_swipe}
\end{figure}

\subsection{評価}
パフォーマンスの後に、


\section{考察}
\subsection{ユーザー視点でのシステムの有効性}

\subsection{実演を通じて明らかになった課題}

\subsection{今後の展望}



\section{おわりに}

本研究では、マシンライブにおける複雑な操作の容易化、即興的なアクセント付けに加え、演奏動作と音響変化の一致による視覚的にも楽しめるといった演奏表現の拡張を可能にするシステムの構築を目指し、ハンドジェスチャーを入力インターフェースとしてMIDIを制御する手法を提案・実装・実演を通して検証した。

提案手法では、MediaPipeを用いて、ハンドサインの自動認識と手指の関節21箇所のカメラ画角内位置座標を取得し、それら情報よってジェスチャーを検出するシステムを構築した。
また、ハンドジェスチャーとそれに対応する音響変化を一致させるために、さまざまな値の動きによるMIDI出力機能の制作に加え、ジェスチャーとそれら機能における自由なパッチングシステムを構築した。

実演では、屋内会場において楽曲『君をのせて』と『紅
蓮華』を演奏し、照明演出の表現力およびリアルタイム性
を検証した。これらの実演を通して、演奏音および演奏動
作に応じて照明が自律的に変化し、演奏と照明が同期する
演出が実現できることを確認した。

実演では、研究室にて、実際のマシンライブ環境に制作したシステムを用いて自作の曲を演奏することで、システムの使いやすさとハンドジェスチャーを用いたことによる表現性の変化を検証した。

以上より、本研究は、音楽演奏と照明演出をリアルタイ
ムに結びつける一つの実践的手法を提示し、演奏者の表現
を視覚的に拡張する可能性を示した点に意義があると結論
づけられる。
